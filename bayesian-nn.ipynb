{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This code is based on https://bit.ly/39LO0jh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global vars\n",
    "dataset_size = 4898\n",
    "train_size = int(dataset_size * 0.85)\n",
    "batch_size = 256\n",
    "hidden_units = [8,8]\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "sample = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_splits(train_size, batch_size=1):\n",
    "\n",
    "    dataset = (\n",
    "        tfds.load(name=\"wine_quality\", as_supervised=True, split=\"train\")\n",
    "        .map(lambda x, y: (x, tf.cast(y, tf.float32)))\n",
    "        .prefetch(buffer_size=dataset_size)\n",
    "        .cache()\n",
    "    )\n",
    "\n",
    "    train_dataset = (\n",
    "        dataset.take(train_size).shuffle(buffer_size=train_size).batch(batch_size)\n",
    "    )\n",
    "    test_dataset = dataset.skip(train_size).batch(batch_size)\n",
    "\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model, loss, train_dataset, test_dataset):\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "        loss=loss,\n",
    "        metrics=[keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "\n",
    "    print(\"Started training the model...\")\n",
    "    history = model.fit(train_dataset, epochs=num_epochs, validation_data=test_dataset)\n",
    "    print(\"Finished training the model\")\n",
    "    _, rmse = model.evaluate(train_dataset, verbose=0)\n",
    "    print(f\"The training rms error is {round(rmse, 3)}\")\n",
    "    _, rmse = model.evaluate(test_dataset, verbose=0)\n",
    "    print(f\"The test rms error is {round(rmse, 3)}\")\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_NAMES = [\n",
    "    \"fixed acidity\",\n",
    "    \"volatile acidity\",\n",
    "    \"citric acid\",\n",
    "    \"residual sugar\",\n",
    "    \"chlorides\",\n",
    "    \"free sulfur dioxide\",\n",
    "    \"total sulfur dioxide\",\n",
    "    \"density\",\n",
    "    \"pH\",\n",
    "    \"sulphates\",\n",
    "    \"alcohol\",\n",
    "]\n",
    "\n",
    "def create_model_inputs():\n",
    "    inputs = {}\n",
    "    for feature_name in FEATURE_NAMES:\n",
    "        inputs[feature_name] = layers.Input(\n",
    "            name=feature_name, shape=(1,), dtype=tf.float32\n",
    "        )\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point estimate BNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior(kernel_size, bias_size, dtype=None):\n",
    "    n = kernel_size + bias_size\n",
    "    prior_model = keras.Sequential(\n",
    "        [\n",
    "            tfp.layers.DistributionLambda(\n",
    "                lambda t: tfp.distributions.MultivariateNormalDiag(\n",
    "                    loc=tf.zeros(n), scale_diag=tf.ones(n)\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    return prior_model\n",
    "\n",
    "def posterior(kernel_size, bias_size, dtype=None):\n",
    "    n = kernel_size + bias_size\n",
    "    posterior_model = keras.Sequential(\n",
    "        [\n",
    "            tfp.layers.VariableLayer(\n",
    "                tfp.layers.MultivariateNormalTriL.params_size(n), \n",
    "                dtype=dtype\n",
    "            ),\n",
    "            tfp.layers.MultivariateNormalTriL(n)\n",
    "        ]\n",
    "    )\n",
    "    return posterior_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bnn_model(train_size):\n",
    "    inputs = create_model_inputs()\n",
    "    features = keras.layers.concatenate(list(inputs.values()))\n",
    "    features = layers.BatchNormalization()(features)\n",
    "\n",
    "    for units in hidden_units:\n",
    "        features = tfp.layers.DenseVariational(\n",
    "            units=units,\n",
    "            make_prior_fn=prior,\n",
    "            make_posterior_fn=posterior,\n",
    "            kl_weight=1 / train_size,\n",
    "            activation=\"sigmoid\"\n",
    "        )(features)\n",
    "    \n",
    "    outputs = layers.Dense(units=1)(features)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = get_splits(train_size, batch_size)\n",
    "small_train_dataset = train_dataset.unbatch().take(train_size).batch(batch_size)\n",
    "bnn_model = create_bnn_model(train_size)\n",
    "mse_loss = keras.losses.MeanSquaredError()\n",
    "run_experiment(bnn_model, mse_loss, small_train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions mean: 5.31, min: 4.38, max: 5.95, range: 1.57, Actual: 4.0\n",
      "Predictions mean: 5.34, min: 4.38, max: 6.13, range: 1.75, Actual: 5.0\n",
      "Predictions mean: 5.37, min: 4.38, max: 6.17, range: 1.79, Actual: 5.0\n",
      "Predictions mean: 6.28, min: 5.52, max: 6.36, range: 0.84, Actual: 7.0\n",
      "Predictions mean: 5.78, min: 4.69, max: 6.32, range: 1.63, Actual: 6.0\n",
      "Predictions mean: 6.17, min: 4.98, max: 6.36, range: 1.37, Actual: 6.0\n",
      "Predictions mean: 6.07, min: 4.98, max: 6.35, range: 1.37, Actual: 7.0\n",
      "Predictions mean: 5.74, min: 4.89, max: 6.27, range: 1.38, Actual: 5.0\n",
      "Predictions mean: 5.99, min: 5.08, max: 6.33, range: 1.25, Actual: 7.0\n",
      "Predictions mean: 5.37, min: 4.59, max: 6.17, range: 1.58, Actual: 5.0\n"
     ]
    }
   ],
   "source": [
    "examples, targets = list(test_dataset\n",
    ".unbatch()\n",
    ".shuffle(batch_size * 10)\n",
    ".batch(sample))[0]\n",
    "def compute_predictions(model, iterations=100):\n",
    "    predicted = []\n",
    "    for _ in range(iterations):\n",
    "        predicted.append(model(examples).numpy())\n",
    "    predicted = np.concatenate(predicted, axis=1)\n",
    "\n",
    "    prediction_mean = np.mean(predicted, axis=1).tolist()\n",
    "    prediction_min = np.min(predicted, axis=1).tolist()\n",
    "    prediction_max = np.max(predicted, axis=1).tolist()\n",
    "    prediction_range = (\n",
    "        np.max(predicted, axis=1) - np.min(predicted, axis=1)\n",
    "    ).tolist()\n",
    "\n",
    "    for idx in range(sample):\n",
    "        print(\n",
    "        f\"Predictions mean: {round(prediction_mean[idx], 2)}, \"\n",
    "        f\"min: {round(prediction_min[idx], 2)}, \"\n",
    "        f\"max: {round(prediction_max[idx], 2)}, \"\n",
    "        f\"range: {round(prediction_range[idx], 2)}, \"\n",
    "        f\"Actual: {targets[idx]}\" \n",
    "        )\n",
    "\n",
    "compute_predictions(bnn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic BNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_probabilistic_bnn_model(train_size, prior_fn=prior):\n",
    "    inputs = create_model_inputs()\n",
    "    features = keras.layers.concatenate(list(inputs.values()))\n",
    "    features = layers.BatchNormalization()(features)\n",
    "\n",
    "    for units in hidden_units:\n",
    "        features = tfp.layers.DenseVariational(\n",
    "            units=units,\n",
    "            make_prior_fn=prior_fn,\n",
    "            make_posterior_fn=posterior,\n",
    "            kl_weight=1 / train_size,\n",
    "            activation=\"sigmoid\"\n",
    "        )(features)\n",
    "    \n",
    "    distribution_params = layers.Dense(units=2)(features)\n",
    "    outputs = tfp.layers.IndependentNormal(1)(distribution_params)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_loglikelihood(targets, estimated_distribution):\n",
    "    return -estimated_distribution.log_prob(targets)\n",
    "\n",
    "num_epochs = 1000\n",
    "prob_bnn_model = create_probabilistic_bnn_model(train_size)\n",
    "history = run_experiment(prob_bnn_model, \n",
    "negative_loglikelihood, \n",
    "train_dataset, \n",
    "test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction mean: 5.31, Stddev: 0.68, 95%CI: [3.97,6.64]Actual: 4.0\n",
      "Prediction mean: 5.31, Stddev: 0.68, 95%CI: [3.97,6.64]Actual: 5.0\n",
      "Prediction mean: 5.41, Stddev: 0.69, 95%CI: [4.06,6.77]Actual: 5.0\n",
      "Prediction mean: 6.24, Stddev: 0.82, 95%CI: [4.63,7.84]Actual: 7.0\n",
      "Prediction mean: 5.47, Stddev: 0.7, 95%CI: [4.09,6.84]Actual: 6.0\n",
      "Prediction mean: 6.02, Stddev: 0.78, 95%CI: [4.49,7.55]Actual: 6.0\n",
      "Prediction mean: 5.61, Stddev: 0.72, 95%CI: [4.2,7.02]Actual: 7.0\n",
      "Prediction mean: 5.56, Stddev: 0.71, 95%CI: [4.16,6.95]Actual: 5.0\n",
      "Prediction mean: 5.9, Stddev: 0.76, 95%CI: [4.4,7.4]Actual: 7.0\n",
      "Prediction mean: 5.33, Stddev: 0.69, 95%CI: [3.99,6.68]Actual: 5.0\n"
     ]
    }
   ],
   "source": [
    "prediction_distribution = prob_bnn_model(examples)\n",
    "prediction_mean = prediction_distribution.mean().numpy().tolist()\n",
    "prediction_std = prediction_distribution.stddev().numpy()\n",
    "\n",
    "upper = (prediction_mean + 1.96 * prediction_std).tolist()\n",
    "lower = (prediction_mean - 1.96 * prediction_std).tolist()\n",
    "prediction_std = prediction_std.tolist()\n",
    "\n",
    "for idx in range(sample):\n",
    "    print(\n",
    "        f\"Prediction mean: {round(prediction_mean[idx][0], 2)}, \"\n",
    "        f\"Stddev: {round(prediction_std[idx][0], 2)}, \"\n",
    "        f\"95%CI: [{round(lower[idx][0], 2)},{round(upper[idx][0], 2)}]\"\n",
    "        f\"Actual: {targets[idx]}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'RMS error')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Training loss')\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"RMS error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=({'alcohol': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'chlorides': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'citric acid': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'density': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'fixed acidity': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'free sulfur dioxide': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'pH': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'residual sugar': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'sulphates': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'total sulfur dioxide': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'volatile acidity': TensorSpec(shape=(None,), dtype=tf.float32, name=None)}, TensorSpec(shape=(None,), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainable_prior(kernel_size, bias_size, dtype=None):\n",
    "    n = kernel_size + bias_size\n",
    "    prior_model = keras.Sequential(\n",
    "        [\n",
    "            tfp.layers.DistributionLambda(\n",
    "        lambda t: tfp.distributions.MultivariateNormalDiag(\n",
    "            loc=t * tf.ones(n), scale_diag=t * tf.ones(n)\n",
    "            )\n",
    "        )\n",
    "        ]\n",
    "    )\n",
    "    return prior_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_bnn_model_trainable = create_probabilistic_bnn_model(train_size, trainable_prior)\n",
    "run_experiment(prob_bnn_model_trainable, \n",
    "negative_loglikelihood, train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_distribution = prob_bnn_model(examples)\n",
    "prediction_mean = prediction_distribution.mean().numpy().tolist()\n",
    "prediction_std = prediction_distribution.stddev().numpy()\n",
    "\n",
    "upper = (prediction_mean + 1.96 * prediction_std).tolist()\n",
    "lower = (prediction_mean - 1.96 * prediction_std).tolist()\n",
    "prediction_std = prediction_std.tolist()\n",
    "\n",
    "for idx in range(sample):\n",
    "    print(\n",
    "        f\"Prediction mean: {round(prediction_mean[idx][0], 2)}, \"\n",
    "        f\"Stddev: {round(prediction_std[idx][0], 2)}, \"\n",
    "        f\"95%CI: [{round(lower[idx][0], 2)},{round(upper[idx][0], 2)}]\"\n",
    "        f\"Actual: {targets[idx]}\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe38411a3bc59f9d2cdd582bb1978bf6bea7ff93d872583d8139a2f42012f8ae"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('mlos')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
